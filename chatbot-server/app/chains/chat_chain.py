from typing import Callable, Awaitable
import asyncio
from app.utils.redis_client import get_session, save_session
from app.db.plan_db import get_all_plans
from app.prompts.get_prompt_template import get_prompt_template
from app.utils.langchain_client import get_chat_model
from langchain_core.output_parsers import StrOutputParser
from app.schemas.chat import ChatRequest

PHONE_PLAN_FLOW = {
    "general": [
        ("data_usage", "ë°ì´í„°ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì‚¬ìš©í•´ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´ìš”, 1ì‹œê°„ ì •ë„, ë§ì´ í•´ìš”)"),
        ("services", "ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ìˆë‚˜ìš”?\n\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ë¡œ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”?\n\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ],
    "muneoz": [
        ("data_usage", "ë°ì´í„° ì–¼ë§ˆë‚˜ ì¨? ğŸ¤Ÿ\n\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì¨ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ í•´? ğŸ“\n\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´, 1ì‹œê°„ ì •ë„, ë§ì´ í•´)"),
        ("services", "ìì£¼ ì“°ëŠ” ì„œë¹„ìŠ¤ ìˆì–´? ğŸ“±\n\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–¼ë§ˆ ì •ë„ ìƒê°í•˜ê³  ìˆì–´? ğŸ’°\n\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ]
}

SUBSCRIPTION_FLOW = {
    "general": [
        ("content_type", "ì–´ë–¤ ì½˜í…ì¸ ë¥¼ ì£¼ë¡œ ì¦ê¸°ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ì–´ë–¤ ê¸°ê¸°ë¡œ ë³´ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ì‹œì²­í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì„ í˜¸í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œê°€ ìˆë‚˜ìš”?\n\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ],
    "muneoz": [
        ("content_type", "ë­˜ ì£¼ë¡œ ë´? ğŸ¬\n\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ë­˜ë¡œ ë´? ğŸ“±\n\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ë´? â°\n\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì¢‹ì•„í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œ ìˆì–´? ğŸ’œ\n\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ]
}

def create_simple_stream(text: str):
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€í™˜"""
    async def stream():
        words = text.split(' ')
        for i, word in enumerate(words):
            yield word
            if i < len(words) - 1:
                yield ' '
            await asyncio.sleep(0.05)
    return stream

async def natural_streaming(text: str):
    """ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë°"""
    words = text.split(' ')
    for i, word in enumerate(words):
        yield word
        if i < len(words) - 1:
            yield ' '
        # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì†ë„
        await asyncio.sleep(0.05)

def get_chain_by_intent(intent: str, req: ChatRequest, tone: str = "general"):
    """ì¸í…íŠ¸ë³„ ì²´ì¸ ë°˜í™˜"""
    print(f"[DEBUG] get_chain_by_intent - intent: {intent}, tone: {tone}")

    session = get_session(req.session_id)
    message = req.message
    session.setdefault("history", [])
    session["history"].append({"role": "user", "content": message})

    # ê¸°ë³¸ ì‘ë‹µë“¤ ì²˜ë¦¬
    if intent == "default":
        if tone == "muneoz":
            default_text = """ì•ˆë‡½! ğŸ¤Ÿ ë‚˜ëŠ” LGìœ í”ŒëŸ¬ìŠ¤ íë ˆì´í„° ë¬´ë„ˆì•¼~ ğŸ™

ìš”ê¸ˆì œë‚˜ êµ¬ë… ì„œë¹„ìŠ¤ ê´€ë ¨í•´ì„œ ë­ë“ ì§€ ë¬¼ì–´ë´!
â€¢ ìš”ê¸ˆì œ ì¶”ì²œ
â€¢ êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ
â€¢ UBTI ì„±í–¥ ë¶„ì„
â€¢ í˜„ì¬ ì‚¬ìš©ëŸ‰ ì²´í¬

ë­˜ ë„ì™€ì¤„ê¹Œ? ğŸ’œ"""
        else:
            default_text = """ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š LGìœ í”ŒëŸ¬ìŠ¤ ìƒë‹´ AIì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ë¥¼ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”:
â€¢ ìš”ê¸ˆì œ ì¶”ì²œ ìƒë‹´
â€¢ êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ
â€¢ UBTI ì„±í–¥ ë¶„ì„ ì•ˆë‚´
â€¢ í˜„ì¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì¶”ì²œ ì•ˆë‚´

ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"""
        return create_simple_stream(default_text)

    elif intent == "greeting":
        if tone == "muneoz":
            greeting_text = """ì•ˆë‡½! ğŸ¤Ÿ ë‚˜ëŠ” ë¬´ë„ˆì•¼~ ğŸ™

ìš”ê¸ˆì œë‘ êµ¬ë… ì „ë¬¸ê°€ë¼ì„œ ì™„ì „ ìì‹  ìˆì–´!

ë­ë“ ì§€ í¸í•˜ê²Œ ë¬¼ì–´ë´~ ğŸ’œ"""
        else:
            greeting_text = """ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜! ğŸ˜Š

ì €ëŠ” LGìœ í”ŒëŸ¬ìŠ¤ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ìš”ê¸ˆì œ ì¶”ì²œë¶€í„° êµ¬ë… ì„œë¹„ìŠ¤ê¹Œì§€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”!

ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"""
        return create_simple_stream(greeting_text)

    # ê¸°ì¡´ ë¡œì§ ê³„ì†
    save_session(req.session_id, session)

    user_info = session.get("user_info", {})
    default_info = {"data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •", "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •"}
    merged_info = {**default_info, **user_info}
    user_info_text = f"""- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}"""

    context = {
        "message": message,
        "user_info": user_info_text,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    if intent.startswith("phone_plan"):
        plans = get_all_plans()
        context["plans"] = "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans])

    elif intent == "subscription_recommend":
        from app.db.subscription_db import get_products_from_db
        from app.db.brand_db import get_life_brands_from_db

        main_items = get_products_from_db()
        life_items = get_life_brands_from_db()

        context["main"] = "\\n\\n".join([
            f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items
        ])
        context["life"] = "\\n\\n".join([
            f"- {b.name}" for b in life_items
        ])

    # toneì„ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    try:
        prompt = get_prompt_template(intent, tone)
        model = get_chat_model()
        chain = prompt | model | StrOutputParser()

        async def stream():
            generated_response = ""
            async for chunk in chain.astream(context):
                if chunk:
                    generated_response += chunk
                    yield chunk
            session["history"].append({"role": "assistant", "content": generated_response})
            save_session(req.session_id, session)

        return stream
    except Exception as e:
        print(f"[ERROR] Chain creation failed: {e}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°± ì‘ë‹µ
        error_text = "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì•—! ë­”ê°€ ê¼¬ì˜€ë‚˜ë´! ë‹¤ì‹œ ë§í•´ì¤˜~ ğŸ˜µ"
        return create_simple_stream(error_text)

async def get_multi_turn_chain(req: ChatRequest, intent: str, tone: str = "general") -> Callable[[], Awaitable[str]]:
    """ë©€í‹°í„´ ì²´ì¸ ì²˜ë¦¬ - ë””ë²„ê¹… ê°•í™”"""

    print(f"[DEBUG] ========== GET_MULTI_TURN_CHAIN START ==========")
    print(f"[DEBUG] Input - intent: '{intent}', tone: '{tone}', message: '{req.message}'")

    try:
        session = get_session(req.session_id)
        message = req.message

        # ì¸í…íŠ¸ë³„ ì§ˆë¬¸ í”Œë¡œìš° ì„ íƒ
        if intent == "phone_plan_multi":
            question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
            flow_key = "phone_plan_flow"
            print(f"[DEBUG] Selected PHONE_PLAN_FLOW for tone '{tone}'")
        elif intent == "subscription_multi":
            question_flow = SUBSCRIPTION_FLOW.get(tone, SUBSCRIPTION_FLOW["general"])
            flow_key = "subscription_flow"
            print(f"[DEBUG] Selected SUBSCRIPTION_FLOW for tone '{tone}'")
        else:
            question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
            flow_key = "phone_plan_flow"
            print(f"[DEBUG] Default to PHONE_PLAN_FLOW for unknown intent '{intent}'")
        if session.get(f"{flow_key}_step", None) not in range(1, len(question_flow)+1):
            session[f"{flow_key}_step"] = 0
            session["user_info"] = {}
            save_session(req.session_id, session)


        # í˜„ì¬ ë‹¨ê³„ í™•ì¸
        current_step = session.get(f"{flow_key}_step", 0)
        user_info = session.get("user_info", {})

        print(f"[DEBUG] Flow state - flow_key: '{flow_key}', current_step: {current_step}")
        print(f"[DEBUG] Current user_info: {user_info}")
        print(f"[DEBUG] Question flow length: {len(question_flow)}")

        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ë©€í‹°í„´ ì‹œì‘ì¸ ê²½ìš°
        if current_step == 0:
            print(f"[DEBUG] >>> STARTING NEW MULTI-TURN FLOW <<<")
            key, question = question_flow[0]
            print(f"[DEBUG] First question - key: '{key}', question: '{question}'")

            session[f"{flow_key}_step"] = 1
            session.setdefault("history", [])
            session["history"].append({"role": "user", "content": message})
            session["history"].append({"role": "assistant", "content": question})
            save_session(req.session_id, session)

            print(f"[DEBUG] Session updated - step set to 1, starting multiturn flow")

            async def stream():
                async for chunk in natural_streaming(question):
                    yield chunk
            return stream

        # ì´ì „ ë‹µë³€ ì €ì¥í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸
        elif current_step > 0 and current_step <= len(question_flow):
            print(f"[DEBUG] >>> CONTINUING MULTI-TURN FLOW (step {current_step}) <<<")

            # ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ ì €ì¥
            prev_key = question_flow[current_step - 1][0]
            user_info[prev_key] = message
            session["user_info"] = user_info
            session.setdefault("history", [])
            session["history"].append({"role": "user", "content": message})

            print(f"[DEBUG] Saved answer - {prev_key}: '{message}'")

            # ë‹¤ìŒ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
            if current_step < len(question_flow):
                key, question = question_flow[current_step]
                print(f"[DEBUG] Next question - key: '{key}', question: '{question}'")

                session[f"{flow_key}_step"] = current_step + 1
                session["history"].append({"role": "assistant", "content": question})
                save_session(req.session_id, session)

                print(f"[DEBUG] Session updated - step set to {current_step + 1}")

                async def stream():
                    async for chunk in natural_streaming(question):
                        yield chunk
                return stream
            else:
                # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ â†’ ìµœì¢… ì¶”ì²œ
                print(f"[DEBUG] >>> ALL QUESTIONS COMPLETED - GENERATING FINAL RECOMMENDATION <<<")

                if intent == "phone_plan_multi":
                    print(f"[DEBUG] Calling get_final_plan_recommendation")
                    return await get_final_plan_recommendation(req, user_info, tone)
                elif intent == "subscription_multi":
                    print(f"[DEBUG] Calling get_final_subscription_recommendation")
                    return await get_final_subscription_recommendation(req, user_info, tone)

        # ì•ˆì „ì¥ì¹˜
        print(f"[DEBUG] >>> UNEXPECTED FLOW STATE - FALLING BACK <<<")
        print(f"[DEBUG] current_step: {current_step}, flow_length: {len(question_flow)}")

        if intent == "phone_plan_multi":
            return await get_final_plan_recommendation(req, user_info, tone)
        elif intent == "subscription_multi":
            return await get_final_subscription_recommendation(req, user_info, tone)

    except Exception as e:
        print(f"[ERROR] Multi-turn chain failed: {e}")
        import traceback
        print(f"[ERROR] Traceback: {traceback.format_exc()}")

        # ì—ëŸ¬ ë°œìƒ ì‹œ í”Œë¡œìš° ì´ˆê¸°í™” ë° ì—ëŸ¬ ì‘ë‹µ
        session = get_session(req.session_id)
        session.pop("phone_plan_flow_step", None)
        session.pop("subscription_flow_step", None)
        save_session(req.session_id, session)

        error_text = "ì£„ì†¡í•´ìš”, ì§ˆë¬¸ ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì•—! ë­”ê°€ ê¼¬ì˜€ë‚˜ë´! ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•´ë³´ì~ ğŸ˜µ"
        return create_simple_stream(error_text)

async def get_final_plan_recommendation(req: ChatRequest, user_info: dict, tone: str = "general"):
    """ìµœì¢… ìš”ê¸ˆì œ ì¶”ì²œ - ì¹´ë“œ ë°ì´í„° í¬í•¨"""
    print(f"[DEBUG] get_final_plan_recommendation - tone: {tone}")

    try:
        session = get_session(req.session_id)
        plans = get_all_plans()

        merged_info = {
            "data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •",
            "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •",
            **user_info
        }

        user_info_text = f"""- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}"""

        context = {
            "user_info": user_info_text,
            "plans": "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans]),
            "message": req.message,
            "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
        }

        prompt = get_prompt_template("phone_plan_multi", tone)
        model = get_chat_model()
        chain = prompt | model | StrOutputParser()

        # ğŸ”¥ í•µì‹¬: ìµœì¢… ì¶”ì²œì„ì„ í‘œì‹œí•˜ëŠ” íŠ¹ë³„í•œ ì‘ë‹µ ìƒì„±
        async def stream():
            generated_response = ""
            try:
                async for chunk in chain.astream(context):
                    if chunk:
                        generated_response += chunk
                        yield chunk
                        await asyncio.sleep(0.01)

                # ğŸ”¥ ìµœì¢… ì¶”ì²œ í‘œì‹œë¥¼ ìœ„í•œ íŠ¹ë³„í•œ ë§ˆì»¤ ì¶”ê°€
                if not any(keyword in generated_response for keyword in ["ì¶”ì²œë“œë¦½ë‹ˆë‹¤", "ì¶”ì²œí•´ë“œë¦´ê²Œ", "ì°°ë–¡ ìš”ê¸ˆì œ"]):
                    # AIê°€ ì¶”ì²œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ê°•ì œë¡œ ì¶”ê°€
                    final_marker = " ìœ„ ìš”ê¸ˆì œë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!" if tone == "general" else " ì´ ìš”ê¸ˆì œë“¤ ì™„ì „ ì¶”ì²œ!"
                    generated_response += final_marker
                    yield final_marker

                session["history"].append({"role": "assistant", "content": generated_response})

                # ğŸ”¥ ìµœì¢… ì¶”ì²œ ì™„ë£Œ í‘œì‹œ
                session["is_final_recommendation"] = True
                session["recommendation_type"] = "plan"

                # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
                session.pop("phone_plan_flow_step", None)
                save_session(req.session_id, session)

            except Exception as e:
                print(f"[ERROR] Final recommendation streaming failed: {e}")
                # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°± ì‘ë‹µ
                fallback_text = "ìš”ê¸ˆì œ ì¶”ì²œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì¶”ì²œí•˜ë‹¤ê°€ ë­”ê°€ ê¼¬ì˜€ì–´! ë‹¤ì‹œ í•´ë³´ì~ ğŸ˜µ"
                yield fallback_text
                session.pop("phone_plan_flow_step", None)
                save_session(req.session_id, session)

        return stream

    except Exception as e:
        print(f"[ERROR] Final plan recommendation setup failed: {e}")
        # ì„¤ì • ë‹¨ê³„ì—ì„œ ì—ëŸ¬ ë°œìƒ ì‹œ
        session = get_session(req.session_id)
        session.pop("phone_plan_flow_step", None)
        save_session(req.session_id, session)

        error_text = "ìš”ê¸ˆì œ ì¶”ì²œ ì¤€ë¹„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì¶”ì²œ ì¤€ë¹„í•˜ë‹¤ê°€ ë­”ê°€ ê¼¬ì˜€ì–´! ë‹¤ì‹œ í•´ë³´ì~ ğŸ˜µ"
        return create_simple_stream(error_text)

async def get_final_subscription_recommendation(req: ChatRequest, user_info: dict, tone: str = "general") -> Callable[[], Awaitable[str]]:
    """ìµœì¢… êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ - ì¹´ë“œ ë°ì´í„° í¬í•¨"""
    print(f"[DEBUG] get_final_subscription_recommendation - tone: {tone}")

    try:
        session = get_session(req.session_id)

        from app.db.subscription_db import get_products_from_db
        from app.db.brand_db import get_life_brands_from_db

        main_items = get_products_from_db()
        life_items = get_life_brands_from_db()

        merged_info = {
            "content_type": "ë¯¸ì„¤ì •", "device_usage": "ë¯¸ì„¤ì •",
            "time_usage": "ë¯¸ì„¤ì •", "preference": "ë¯¸ì„¤ì •",
            **user_info
        }

        user_info_text = f"""- ì„ í˜¸ ì½˜í…ì¸ : {merged_info['content_type']}\\n\\n- ì‚¬ìš© ê¸°ê¸°: {merged_info['device_usage']}\\n\\n- ì‹œì²­ ì‹œê°„: {merged_info['time_usage']}\\n\\n- ì„ í˜¸ ì¥ë¥´/ë¸Œëœë“œ: {merged_info['preference']}"""

        context = {
            "main": "\\n\\n".join([f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items]),
            "life": "\\n\\n".join([f"- {b.name}" for b in life_items]),
            "user_info": user_info_text,
            "message": req.message,
            "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
        }

        prompt = get_prompt_template("subscription_recommend", tone)
        model = get_chat_model()
        chain = prompt | model | StrOutputParser()

        # í•µì‹¬: ìµœì¢… ì¶”ì²œì„ì„ í‘œì‹œí•˜ëŠ” íŠ¹ë³„í•œ ì‘ë‹µ ìƒì„±
        async def stream():
            generated_response = ""
            try:
                async for chunk in chain.astream(context):
                    if chunk:
                        generated_response += chunk
                        yield chunk
                        await asyncio.sleep(0.01)

                # ìµœì¢… ì¶”ì²œ í‘œì‹œë¥¼ ìœ„í•œ íŠ¹ë³„í•œ ë§ˆì»¤ ì¶”ê°€
                if not any(keyword in generated_response for keyword in ["ì¶”ì²œë“œë¦½ë‹ˆë‹¤", "ì¶”ì²œí•´ë“œë¦´ê²Œ", "ì°°ë–¡", "ìœ„ ì¡°í•©ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤", "ì´ ì¡°í•© ì™„ì „ ì¶”ì²œ"]):
                    final_marker = " ìœ„ ì¡°í•©ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!" if tone == "general" else " ì´ ì¡°í•© ì™„ì „ ì¶”ì²œ!"
                    generated_response += final_marker
                    yield final_marker

                session["history"].append({"role": "assistant", "content": generated_response})

                # ìµœì¢… ì¶”ì²œ ì™„ë£Œ í‘œì‹œ
                session["is_final_recommendation"] = True
                session["recommendation_type"] = "subscription"

                # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
                session.pop("subscription_flow_step", None)
                save_session(req.session_id, session)

            except Exception as e:
                print(f"[ERROR] Final subscription streaming failed: {e}")
                # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°± ì‘ë‹µ
                fallback_text = "êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì¶”ì²œí•˜ë‹¤ê°€ ë­”ê°€ ê¼¬ì˜€ì–´! ë‹¤ì‹œ í•´ë³´ì~ ğŸ˜µ"
                yield fallback_text
                session.pop("subscription_flow_step", None)
                save_session(req.session_id, session)

        return stream

    except Exception as e:
        print(f"[ERROR] Final subscription recommendation setup failed: {e}")
        # ì„¤ì • ë‹¨ê³„ì—ì„œ ì—ëŸ¬ ë°œìƒ ì‹œ
        session = get_session(req.session_id)
        session.pop("subscription_flow_step", None)
        save_session(req.session_id, session)

        error_text = "êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ ì¤€ë¹„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜…" if tone == "general" else "ì¶”ì²œ ì¤€ë¹„í•˜ë‹¤ê°€ ë­”ê°€ ê¼¬ì˜€ì–´! ë‹¤ì‹œ í•´ë³´ì~ ğŸ˜µ"
        return create_simple_stream(error_text)