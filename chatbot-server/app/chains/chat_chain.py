# app/chains/chat_chain.py (ì™„ì „ ì¬ì‘ì„±)
from typing import Callable, Awaitable
import asyncio
from app.utils.redis_client import get_session, save_session
from app.db.plan_db import get_all_plans
from app.prompts.get_prompt_template import get_prompt_template
from app.utils.langchain_client import get_chat_model
from langchain_core.output_parsers import StrOutputParser
from app.schemas.chat import ChatRequest

PHONE_PLAN_FLOW = {
    "general": [
        ("data_usage", "ë°ì´í„°ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì‚¬ìš©í•´ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´ìš”, 1ì‹œê°„ ì •ë„, ë§ì´ í•´ìš”)"),
        ("services", "ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ìˆë‚˜ìš”?\n\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ë¡œ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”?\n\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ],
    "muneoz": [
        ("data_usage", "ë°ì´í„° ì–¼ë§ˆë‚˜ ì¨? ğŸ¤Ÿ\n\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì¨ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ í•´? ğŸ“\n\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´, 1ì‹œê°„ ì •ë„, ë§ì´ í•´)"),
        ("services", "ìì£¼ ì“°ëŠ” ì„œë¹„ìŠ¤ ìˆì–´? ğŸ“±\n\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–¼ë§ˆ ì •ë„ ìƒê°í•˜ê³  ìˆì–´? ğŸ’°\n\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ]
}

SUBSCRIPTION_FLOW = {
    "general": [
        ("content_type", "ì–´ë–¤ ì½˜í…ì¸ ë¥¼ ì£¼ë¡œ ì¦ê¸°ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ì–´ë–¤ ê¸°ê¸°ë¡œ ë³´ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ì‹œì²­í•˜ì‹œë‚˜ìš”?\n\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì„ í˜¸í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œê°€ ìˆë‚˜ìš”?\n\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ],
    "muneoz": [
        ("content_type", "ë­˜ ì£¼ë¡œ ë´? ğŸ¬\n\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ë­˜ë¡œ ë´? ğŸ“±\n\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ë´? â°\n\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì¢‹ì•„í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œ ìˆì–´? ğŸ’œ\n\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ]
}

def create_simple_stream(text: str):
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€í™˜"""
    async def stream():
        words = text.split(' ')
        for i, word in enumerate(words):
            yield word
            if i < len(words) - 1:
                yield ' '
            await asyncio.sleep(0.05)
    return stream

async def natural_streaming(text: str):
    """ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë°"""
    words = text.split(' ')
    for i, word in enumerate(words):
        yield word
        if i < len(words) - 1:
            yield ' '
        # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì†ë„
        await asyncio.sleep(0.05)

def get_chain_by_intent(intent: str, req: ChatRequest, tone: str = "general"):
    """ì¸í…íŠ¸ë³„ ì²´ì¸ ë°˜í™˜"""
    print(f"[DEBUG] get_chain_by_intent - intent: {intent}, tone: {tone}")

    session = get_session(req.session_id)
    message = req.message
    session.setdefault("history", [])
    session["history"].append({"role": "user", "content": message})

    # ê¸°ë³¸ ì‘ë‹µë“¤ ì²˜ë¦¬
    if intent == "default":
        if tone == "muneoz":
            default_text = """ì•ˆë‡½! ğŸ¤Ÿ ë‚˜ëŠ” LGìœ í”ŒëŸ¬ìŠ¤ íë ˆì´í„° ë¬´ë„ˆì•¼~ ğŸ™

ìš”ê¸ˆì œë‚˜ êµ¬ë… ì„œë¹„ìŠ¤ ê´€ë ¨í•´ì„œ ë­ë“ ì§€ ë¬¼ì–´ë´!
â€¢ ìš”ê¸ˆì œ ì¶”ì²œ
â€¢ êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ  
â€¢ UBTI ì„±í–¥ ë¶„ì„
â€¢ í˜„ì¬ ì‚¬ìš©ëŸ‰ ì²´í¬

ë­˜ ë„ì™€ì¤„ê¹Œ? ğŸ’œ"""
        else:
            default_text = """ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š LGìœ í”ŒëŸ¬ìŠ¤ ìƒë‹´ AIì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ë¥¼ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”:
â€¢ ìš”ê¸ˆì œ ì¶”ì²œ ìƒë‹´
â€¢ êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ
â€¢ UBTI ì„±í–¥ ë¶„ì„ ì•ˆë‚´
â€¢ í˜„ì¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì¶”ì²œ ì•ˆë‚´

ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"""
        return create_simple_stream(default_text)

    elif intent == "greeting":
        if tone == "muneoz":
            greeting_text = """ì•ˆë‡½! ğŸ¤Ÿ ë‚˜ëŠ” ë¬´ë„ˆì•¼~ ğŸ™

ìš”ê¸ˆì œë‘ êµ¬ë… ì „ë¬¸ê°€ë¼ì„œ ì™„ì „ ìì‹  ìˆì–´!

ë­ë“ ì§€ í¸í•˜ê²Œ ë¬¼ì–´ë´~ ğŸ’œ"""
        else:
            greeting_text = """ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜! ğŸ˜Š

ì €ëŠ” LGìœ í”ŒëŸ¬ìŠ¤ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ìš”ê¸ˆì œ ì¶”ì²œë¶€í„° êµ¬ë… ì„œë¹„ìŠ¤ê¹Œì§€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”!

ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"""
        return create_simple_stream(greeting_text)

    # ê¸°ì¡´ ë¡œì§ ê³„ì†
    save_session(req.session_id, session)

    user_info = session.get("user_info", {})
    default_info = {"data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •", "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •"}
    merged_info = {**default_info, **user_info}
    user_info_text = f"""- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}"""

    context = {
        "message": message,
        "user_info": user_info_text,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    if intent.startswith("phone_plan"):
        plans = get_all_plans()
        context["plans"] = "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans])

    elif intent == "subscription_recommend":
        from app.db.subscription_db import get_products_from_db
        from app.db.brand_db import get_life_brands_from_db

        main_items = get_products_from_db()
        life_items = get_life_brands_from_db()

        context["main"] = "\\n\\n".join([
            f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items
        ])
        context["life"] = "\\n\\n".join([
            f"- {b.name}" for b in life_items
        ])

    # toneì„ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    prompt = get_prompt_template(intent, tone)
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
        session["history"].append({"role": "assistant", "content": generated_response})
        save_session(req.session_id, session)

    return stream

async def get_multi_turn_chain(req: ChatRequest, intent: str, tone: str = "general") -> Callable[[], Awaitable[str]]:
    """ë©€í‹°í„´ ì²´ì¸ ì²˜ë¦¬"""
    print(f"[DEBUG] get_multi_turn_chain - intent: {intent}, tone: {tone}")

    session = get_session(req.session_id)
    message = req.message

    # ì¸í…íŠ¸ë³„ ì§ˆë¬¸ í”Œë¡œìš° ì„ íƒ
    if intent == "phone_plan_multi":
        question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
        flow_key = "phone_plan_flow"
    elif intent == "subscription_multi":
        question_flow = SUBSCRIPTION_FLOW.get(tone, SUBSCRIPTION_FLOW["general"])
        flow_key = "subscription_flow"
    else:
        question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
        flow_key = "phone_plan_flow"

    # í˜„ì¬ ë‹¨ê³„ í™•ì¸
    current_step = session.get(f"{flow_key}_step", 0)
    user_info = session.get("user_info", {})

    print(f"[DEBUG] Intent: {intent}, Current Step: {current_step}, Message: {message}")

    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ë©€í‹°í„´ ì‹œì‘ì¸ ê²½ìš°
    if current_step == 0:
        key, question = question_flow[0]
        session[f"{flow_key}_step"] = 1
        session.setdefault("history", [])
        session["history"].append({"role": "user", "content": message})
        session["history"].append({"role": "assistant", "content": question})
        save_session(req.session_id, session)

        print(f"[DEBUG] Starting multiturn flow, asking first question")

        async def stream():
            async for chunk in natural_streaming(question):
                yield chunk
        return stream

    # ì´ì „ ë‹µë³€ ì €ì¥í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸
    elif current_step > 0 and current_step <= len(question_flow):
        # ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ ì €ì¥
        prev_key = question_flow[current_step - 1][0]
        user_info[prev_key] = message
        session["user_info"] = user_info
        session.setdefault("history", [])
        session["history"].append({"role": "user", "content": message})

        print(f"[DEBUG] Saved {prev_key}: {message}")

        # ë‹¤ìŒ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
        if current_step < len(question_flow):
            key, question = question_flow[current_step]
            session[f"{flow_key}_step"] = current_step + 1
            session["history"].append({"role": "assistant", "content": question})
            save_session(req.session_id, session)

            print(f"[DEBUG] Asking next question (step {current_step + 1})")

            async def stream():
                async for chunk in natural_streaming(question):
                    yield chunk
            return stream
        else:
            # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ â†’ ìµœì¢… ì¶”ì²œ
            print(f"[DEBUG] All questions completed. Generating final recommendation...")

            if intent == "phone_plan_multi":
                return await get_final_plan_recommendation(req, user_info, tone)
            elif intent == "subscription_multi":
                return await get_final_subscription_recommendation(req, user_info, tone)

    # ì•ˆì „ì¥ì¹˜
    print(f"[DEBUG] Unexpected flow state - falling back to final recommendation")
    if intent == "phone_plan_multi":
        return await get_final_plan_recommendation(req, user_info, tone)
    elif intent == "subscription_multi":
        return await get_final_subscription_recommendation(req, user_info, tone)

async def get_final_plan_recommendation(req: ChatRequest, user_info: dict, tone: str = "general"):
    """ìµœì¢… ìš”ê¸ˆì œ ì¶”ì²œ"""
    print(f"[DEBUG] get_final_plan_recommendation - tone: {tone}")

    session = get_session(req.session_id)
    plans = get_all_plans()

    merged_info = {
        "data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •",
        "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •",
        **user_info
    }

    user_info_text = f"""- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}"""

    context = {
        "user_info": user_info_text,
        "plans": "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans]),
        "message": req.message,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    prompt = get_prompt_template("phone_plan_multi", tone)
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
                await asyncio.sleep(0.01)

        session["history"].append({"role": "assistant", "content": generated_response})
        # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
        session.pop("phone_plan_flow_step", None)
        save_session(req.session_id, session)

    return stream

async def get_final_subscription_recommendation(req: ChatRequest, user_info: dict, tone: str = "general") -> Callable[[], Awaitable[str]]:
    """ìµœì¢… êµ¬ë… ì„œë¹„ìŠ¤ ì¶”ì²œ"""
    print(f"[DEBUG] get_final_subscription_recommendation - tone: {tone}")

    session = get_session(req.session_id)

    from app.db.subscription_db import get_products_from_db
    from app.db.brand_db import get_life_brands_from_db

    main_items = get_products_from_db()
    life_items = get_life_brands_from_db()

    merged_info = {
        "content_type": "ë¯¸ì„¤ì •", "device_usage": "ë¯¸ì„¤ì •",
        "time_usage": "ë¯¸ì„¤ì •", "preference": "ë¯¸ì„¤ì •",
        **user_info
    }

    user_info_text = f"""- ì„ í˜¸ ì½˜í…ì¸ : {merged_info['content_type']}\\n\\n- ì‚¬ìš© ê¸°ê¸°: {merged_info['device_usage']}\\n\\n- ì‹œì²­ ì‹œê°„: {merged_info['time_usage']}\\n\\n- ì„ í˜¸ ì¥ë¥´/ë¸Œëœë“œ: {merged_info['preference']}"""

    context = {
        "main": "\\n\\n".join([f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items]),
        "life": "\\n\\n".join([f"- {b.name}" for b in life_items]),
        "user_info": user_info_text,
        "message": req.message,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    prompt = get_prompt_template("subscription_recommend", tone)
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
                await asyncio.sleep(0.01)

        session["history"].append({"role": "assistant", "content": generated_response})
        # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
        session.pop("subscription_flow_step", None)
        save_session(req.session_id, session)

    return stream