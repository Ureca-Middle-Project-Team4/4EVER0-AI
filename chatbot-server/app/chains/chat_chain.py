from typing import Callable, Awaitable
import asyncio
from app.utils.redis_client import get_session, save_session
from app.db.plan_db import get_all_plans
from app.prompts.get_prompt_template import get_prompt_template
from app.utils.langchain_client import get_chat_model
from langchain_core.output_parsers import StrOutputParser
from app.schemas.chat import ChatRequest

# ìš”ê¸ˆì œ ì§ˆë¬¸ í”Œë¡œìš° - ë§íˆ¬ë³„ë¡œ ë¶„ë¦¬
PHONE_PLAN_FLOW = {
    "general": [
        ("data_usage", "ë°ì´í„°ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\\n\\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì‚¬ìš©í•´ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?\\n\\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´ìš”, 1ì‹œê°„ ì •ë„, ë§ì´ í•´ìš”)"),
        ("services", "ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ìˆë‚˜ìš”?\\n\\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ë¡œ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”?\\n\\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ],
    "muneoz": [
        ("data_usage", "ë°ì´í„° ì–¼ë§ˆë‚˜ ì¨? ğŸ¤Ÿ\\n\\n(ì˜ˆ: 5GB, ë¬´ì œí•œ, ë§ì´ ì¨ìš”)"),
        ("call_usage", "í†µí™”ëŠ” ì–¼ë§ˆë‚˜ í•´? ğŸ“\\n\\n(ì˜ˆ: ê±°ì˜ ì•ˆí•´, 1ì‹œê°„ ì •ë„, ë§ì´ í•´)"),
        ("services", "ìì£¼ ì“°ëŠ” ì„œë¹„ìŠ¤ ìˆì–´? ğŸ“±\\n\\n(ì˜ˆ: ìœ íŠœë¸Œ, ê²Œì„, SNS, ì—…ë¬´ìš©)"),
        ("budget", "ì˜ˆì‚°ì€ ì–¼ë§ˆ ì •ë„ ìƒê°í•˜ê³  ìˆì–´? ğŸ’°\\n\\n(ì˜ˆ: 3ë§Œì›ëŒ€, 5ë§Œì› ì´í•˜)")
    ]
}

# êµ¬ë… ì„œë¹„ìŠ¤ ì§ˆë¬¸ í”Œë¡œìš° - ë§íˆ¬ë³„ë¡œ ë¶„ë¦¬
SUBSCRIPTION_FLOW = {
    "general": [
        ("content_type", "ì–´ë–¤ ì½˜í…ì¸ ë¥¼ ì£¼ë¡œ ì¦ê¸°ì‹œë‚˜ìš”?\\n\\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ì–´ë–¤ ê¸°ê¸°ë¡œ ë³´ì‹œë‚˜ìš”?\\n\\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ì‹œì²­í•˜ì‹œë‚˜ìš”?\\n\\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì„ í˜¸í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œê°€ ìˆë‚˜ìš”?\\n\\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ],
    "muneoz": [
        ("content_type", "ë­˜ ì£¼ë¡œ ë´? ğŸ¬\\n\\n(ì˜ˆ: ë“œë¼ë§ˆ, ì˜í™”, ìŒì•…, ìŠ¤í¬ì¸ )"),
        ("device_usage", "ì£¼ë¡œ ë­˜ë¡œ ë´? ğŸ“±\\n\\n(ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, TV, íƒœë¸”ë¦¿)"),
        ("time_usage", "ì–¸ì œ ì£¼ë¡œ ë´? â°\\n\\n(ì˜ˆ: ì¶œí‡´ê·¼ì‹œê°„, ì €ë…ì‹œê°„, ì£¼ë§)"),
        ("preference", "ì¢‹ì•„í•˜ëŠ” ì¥ë¥´ë‚˜ íŠ¹ë³„íˆ ê´€ì‹¬ìˆëŠ” ë¸Œëœë“œ ìˆì–´? ğŸ’œ\\n\\n(ì˜ˆ: ì•¡ì…˜, ë¡œë§¨ìŠ¤, íŠ¹ì • ì±„ë„)")
    ]
}

def detect_intent(message: str) -> str:
    """ê°„ë‹¨í•œ ì¸í…íŠ¸ ê°ì§€"""
    lowered = message.lower()

    # ì¸ì‚¬ ê°ì§€
    if any(word in lowered for word in ["ì•ˆë…•", "ë°˜ê°‘", "hi", "hello"]):
        return "greeting"

    if "êµ¬ë…" in lowered:
        return "subscription_recommend"
    if any(word in lowered for word in ["ìš”ê¸ˆì œ", "ë¬´ì œí•œ", "5g", "lte", "ì˜ìƒ", "ì „í™”", "ì–¼ë§ˆ"]):
        return "phone_plan_recommend"
    return "default"


async def natural_streaming(text: str):
    """ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë°"""
    words = text.split(' ')
    for i, word in enumerate(words):
        yield word
        if i < len(words) - 1:
            yield ' '
        # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì†ë„
        await asyncio.sleep(0.05)


def get_chain_by_intent(intent: str, req: ChatRequest, tone: str = "general"):
    print(f"[DEBUG] get_chain_by_intent - intent: {intent}, tone: {tone}")

    session = get_session(req.session_id)
    message = req.message
    session.setdefault("history", [])
    session["history"].append({"role": "user", "content": message})

    # ë©€í‹°í„´ ì²˜ë¦¬
    if intent in ["phone_plan_multi", "subscription_multi"]:
        return get_multi_turn_chain(req, intent, tone)  # tone ì¶”ê°€

    save_session(req.session_id, session)

    # ê¸°ì¡´ ë‹¨ì¼ ì‘ë‹µ ë¡œì§
    user_info = session.get("user_info", {})
    default_info = {"data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •", "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •"}
    merged_info = {**default_info, **user_info}
    user_info_text = f"""\
- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}
"""

    context = {
        "message": message,
        "user_info": user_info_text,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    if intent.startswith("phone_plan"):
        plans = get_all_plans()
        context["plans"] = "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans])

    elif intent == "subscription_recommend":
        from app.db.subscription_db import get_products_from_db
        from app.db.brand_db import get_life_brands_from_db

        main_items = get_products_from_db()
        life_items = get_life_brands_from_db()

        context["main"] = "\\n\\n".join([
            f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items
        ])
        context["life"] = "\\n\\n".join([
            f"- {b.name}" for b in life_items
        ])

    # toneì„ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ ì„ íƒ (ì¤‘ë³µ ì œê±°)
    prompt = get_prompt_template(intent, tone)  # tone íŒŒë¼ë¯¸í„° ì¶”ê°€
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
        session["history"].append({"role": "assistant", "content": generated_response})
        save_session(req.session_id, session)

    return stream


async def get_multi_turn_chain(req: ChatRequest, intent: str, tone: str = "general") -> Callable[[], Awaitable[str]]:
    print(f"[DEBUG] get_multi_turn_chain - intent: {intent}, tone: {tone}")

    session = get_session(req.session_id)
    message = req.message

    # ì¸í…íŠ¸ë³„ ì§ˆë¬¸ í”Œë¡œìš° ì„ íƒ (ë§íˆ¬ ê³ ë ¤)
    if intent == "phone_plan_multi":
        question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
        flow_key = "phone_plan_flow"
    elif intent == "subscription_multi":
        question_flow = SUBSCRIPTION_FLOW.get(tone, SUBSCRIPTION_FLOW["general"])
        flow_key = "subscription_flow"
    else:
        question_flow = PHONE_PLAN_FLOW.get(tone, PHONE_PLAN_FLOW["general"])
        flow_key = "phone_plan_flow"

    # í˜„ì¬ ë‹¨ê³„ í™•ì¸
    current_step = session.get(f"{flow_key}_step", 0)
    user_info = session.get("user_info", {})

    print(f"[DEBUG] Intent: {intent}, Current Step: {current_step}, Message: {message}")

    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ë©€í‹°í„´ ì‹œì‘ì¸ ê²½ìš°
    if current_step == 0:
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‹œì‘
        key, question = question_flow[0]
        session[f"{flow_key}_step"] = 1
        session.setdefault("history", [])
        session["history"].append({"role": "user", "content": message})
        session["history"].append({"role": "assistant", "content": question})
        save_session(req.session_id, session)

        print(f"[DEBUG] Starting multiturn flow, asking first question: {question[:50]}...")

        async def stream():
            async for chunk in natural_streaming(question):
                yield chunk
        return stream

    # ì´ì „ ë‹µë³€ ì €ì¥í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸
    elif current_step > 0 and current_step <= len(question_flow):
        # ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ ì €ì¥
        prev_key = question_flow[current_step - 1][0]
        user_info[prev_key] = message
        session["user_info"] = user_info
        session.setdefault("history", [])
        session["history"].append({"role": "user", "content": message})

        print(f"[DEBUG] Saved {prev_key}: {message}")
        print(f"[DEBUG] Current user_info: {user_info}")

        # ë‹¤ìŒ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
        if current_step < len(question_flow):
            key, question = question_flow[current_step]
            session[f"{flow_key}_step"] = current_step + 1
            session["history"].append({"role": "assistant", "content": question})
            save_session(req.session_id, session)

            print(f"[DEBUG] Asking next question (step {current_step + 1}): {question[:50]}...")

            async def stream():
                async for chunk in natural_streaming(question):
                    yield chunk
            return stream
        else:
            # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ â†’ ìµœì¢… ì¶”ì²œ
            print(f"[DEBUG] All questions completed. Generating final recommendation...")

            if intent == "phone_plan_multi":
                return await get_final_plan_recommendation(req, user_info, tone)
            elif intent == "subscription_multi":
                return await get_final_subscription_recommendation(req, user_info, tone)

    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ ì•ˆë˜ì§€ë§Œ ì•ˆì „ì¥ì¹˜
    print(f"[DEBUG] Unexpected flow state - falling back to final recommendation")
    if intent == "phone_plan_multi":
        return await get_final_plan_recommendation(req, user_info, tone)
    elif intent == "subscription_multi":
        return await get_final_subscription_recommendation(req, user_info, tone)


async def get_final_plan_recommendation(req: ChatRequest, user_info: dict, tone: str = "general"):
    print(f"[DEBUG] get_final_plan_recommendation - tone: {tone}")

    session = get_session(req.session_id)
    plans = get_all_plans()

    merged_info = {
        "data_usage": "ë¯¸ì„¤ì •", "call_usage": "ë¯¸ì„¤ì •",
        "services": "ë¯¸ì„¤ì •", "budget": "ë¯¸ì„¤ì •",
        **user_info
    }

    print(f"[DEBUG] Final recommendation with user_info: {merged_info}")

    user_info_text = f"""\
- ë°ì´í„° ì‚¬ìš©ëŸ‰: {merged_info['data_usage']}\\n\\n- í†µí™” ì‚¬ìš©ëŸ‰: {merged_info['call_usage']}\\n\\n- ì„ í˜¸ ì„œë¹„ìŠ¤: {merged_info['services']}\\n\\n- ì˜ˆì‚°: {merged_info['budget']}
"""

    context = {
        "user_info": user_info_text,
        "plans": "\\n\\n".join([f"- {p.name} / {p.price} / {p.data} / {p.voice}" for p in plans]),
        "message": req.message,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    prompt = get_prompt_template("phone_plan_multi", tone)  # tone ì¶”ê°€
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
                # ìŠ¤íŠ¸ë¦¬ë° ì†ë„ ì¡°ì ˆ
                await asyncio.sleep(0.01)

        session["history"].append({"role": "assistant", "content": generated_response})
        # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
        session.pop("phone_plan_flow_step", None)
        # user_infoëŠ” ìœ ì§€ (ë‹¤ìŒ ëŒ€í™”ì—ì„œ í™œìš© ê°€ëŠ¥)
        save_session(req.session_id, session)

        print(f"[DEBUG] Plan recommendation completed and session saved")

    return stream


async def get_final_subscription_recommendation(req: ChatRequest, user_info: dict, tone: str = "general") -> Callable[[], Awaitable[str]]:
    print(f"[DEBUG] get_final_subscription_recommendation - tone: {tone}")

    session = get_session(req.session_id)

    from app.db.subscription_db import get_products_from_db
    from app.db.brand_db import get_life_brands_from_db

    main_items = get_products_from_db()
    life_items = get_life_brands_from_db()

    merged_info = {
        "content_type": "ë¯¸ì„¤ì •", "device_usage": "ë¯¸ì„¤ì •",
        "time_usage": "ë¯¸ì„¤ì •", "preference": "ë¯¸ì„¤ì •",
        **user_info
    }

    print(f"[DEBUG] Final subscription recommendation with user_info: {merged_info}")

    user_info_text = f"""\
- ì„ í˜¸ ì½˜í…ì¸ : {merged_info['content_type']}\\n\\n- ì‚¬ìš© ê¸°ê¸°: {merged_info['device_usage']}\\n\\n- ì‹œì²­ ì‹œê°„: {merged_info['time_usage']}\\n\\n- ì„ í˜¸ ì¥ë¥´/ë¸Œëœë“œ: {merged_info['preference']}
"""

    context = {
        "main": "\\n\\n".join([f"- {p.title} ({p.category}) - {p.price}ì›" for p in main_items]),
        "life": "\\n\\n".join([f"- {b.name}" for b in life_items]),
        "user_info": user_info_text,
        "message": req.message,
        "history": "\\n\\n".join([f"{m['role']}: {m['content']}" for m in session["history"]])
    }

    prompt = get_prompt_template("subscription_recommend", tone)  # tone ì¶”ê°€
    model = get_chat_model()
    chain = prompt | model | StrOutputParser()

    async def stream():
        generated_response = ""
        async for chunk in chain.astream(context):
            if chunk:
                generated_response += chunk
                yield chunk
                # ìŠ¤íŠ¸ë¦¬ë° ì†ë„ ì¡°ì ˆ
                await asyncio.sleep(0.01)

        session["history"].append({"role": "assistant", "content": generated_response})
        # í”Œë¡œìš° ì™„ë£Œ í›„ ì´ˆê¸°í™”
        session.pop("subscription_flow_step", None)
        # user_infoëŠ” ìœ ì§€ (ë‹¤ìŒ ëŒ€í™”ì—ì„œ í™œìš© ê°€ëŠ¥)
        save_session(req.session_id, session)

        print(f"[DEBUG] Subscription recommendation completed and session saved")

    return stream


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ í•¨ìˆ˜
async def get_multi_turn_chain_legacy(req: ChatRequest) -> Callable[[], Awaitable[str]]:
    """ê¸°ì¡´ ìš”ê¸ˆì œ ë©€í‹°í„´ í•¨ìˆ˜ (í˜¸í™˜ì„± ìœ ì§€)"""
    return await get_multi_turn_chain(req, "phone_plan_multi", "general")